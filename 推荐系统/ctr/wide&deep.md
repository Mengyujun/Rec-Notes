# wide&deep

一句话概括： 

**W&D由浅层（或单层）的Wide部分神经网络和深层的Deep部分多层神经网络组成，输出层采用softmax或logistics regression综合Wide和Deep部分的输出。**



### 模型图：

![img](https://pic1.zhimg.com/v2-a203aa626f77d0510bbffa5535c34d7d_b.jpg)



### **优点：**

**Wide**部分有利于增强模型的“**记忆能力**”，**Deep**部分有利于增强模型的“**泛化能力**”

Wide部分只需补充Deep模型的缺点，即记忆能力，这部分主要通过**小规模的交叉特征**实现



### 细节：

1. **使用带L1正则化项的FTRL作为wide部分的优化方法，而使用AdaGrad作为deep部分的优化方法** 

   - **FTRL with L1非常注重模型的稀疏性**，即想让wide部分变得更加稀疏，即L1 FTRL会让Wide部分的大部分权重都为0，压缩了模型权重，也压缩了特征向量的维度
   - Deep部分呢： 输入主要是**数值型特征** or 已经**降维并稠密化的Embedding向量**, 不会有过度稀疏的特征向量， 即不存在严重的**特征稀疏问题**， **深度学习模型不需要稀疏性，稀疏性太强影响效果**

2. 记忆能力和泛化能力如何理解？

   - 记忆能力 指 “直接的”、“暴力的”、“显然的”关联规则的能力 ------即很容易理解强关联的规则-- （论文原义是-频繁共现的特征 或者  历史数据中可以体现的特征）
   - 泛化能力 指 所有特征交给网络去学习是否关联， 泛化成一些间接的，可能的相关性-- （论文解释- 基于特征相关性的传递性 以及 探索之前没有在历史数据中出现过的特征组合）
   - 其实分别对应了 推荐结果**准确性（记忆能力）和扩展性（泛化能力）**

3. 两部分的输入有何区别呢 

   - wide侧说白了就是记忆用的，还是**one-hot**更合适，能够很明确的告诉模型去记忆什么  --**one-hot 后的离散型特征和等频分桶后的连续性特征  以及一些交叉特征**   其中 **交叉特征**是最重要的
   - wide侧肯定是**独热输入**，embedding其实就是一层全连接神经网络
   - Deep侧  可以泛化学习到样本中多个特征之间与目标看不到的潜在关联-- **Embedding 后的离散型特征和归一化后的连续型特征**

4. wide部分具体

   wide部分主要就是一个**广义线性模型（如LR）**，具体模型如下：

   ![image-20201103110135823](https://i.loli.net/2020/11/03/Zjynrm8RK9dGcHx.png)

   ​																							Wide部分模型

   这里值得注意的是，这部分的输入特征包括两部分，一部分是原始的输入特征，另一部分是交叉特征，

   **Wide侧还需要人工构造特征交叉**（deepfm对wide&deep的巨大改进， 不需要再手动交叉）

   其中一种方式就是cross-product，具体定义如下：

   ![](https://i.loli.net/2020/11/03/axgGoUEvMwKQc76.png)

   上式即特征交叉， 主要作用------捕获特征之间的关系，以及增加广义线性模型的非线性 

5. deep部分具体

   Deep部分简单理解就是Embedding+MLP这种非常普遍的结构

   具体模型结构如下所示：

   ![image-20201103111914447](https://i.loli.net/2020/11/03/dh4NRV7WZUMc3QY.png)

   从上图的网络结构可以看出，中间隐藏层的激活函数都是ReLu，最后一层的激活函数是sigmoid

   模型的输入-- 类别型特征都要转化为 embedding 特征 

6. 训练过程为联合训练

   即同时训练wide 和deep部分的模型参数，wide部分主要采用带L1正则的FTRL算法进行优化,deep部分采用AdaGrad进行优化 

   好处如下：

   - 整体最优化
   - 有效降低整个网络大小

7. 系统实现 - google play 推荐系统**实际实现**

   ![image-20201103144056390](https://i.loli.net/2020/11/03/aoJGPyFAj7ehmUx.png)

   data-generation  --准备数据 且 数据处理（一些类别型特征转化为 id类  连续型特征做归一化等操作 ）

   training --  如上图所示  注意里面的各种输入 ：

   - wide侧 ： 一个交叉特征（installed & impression app）
   - deep侧 ：
     -  **类别型特征**去学习32维的embedding特征  
     - **连续型特征**直接 和之后的embedding特征 **concat**  	

   model serving --  多线程并行来降低serve的延时 