### 2. 评价指标 相关知识 

#### AUC两种定义

1. roc曲线下的面积，roc曲线的纵坐标是 真阳率 横坐标是伪阳率
   涉及到混淆矩阵，一些相关定义

   ![](https://pic3.zhimg.com/80/v2-a253b01cf7f141b9ad11eefdf3cf58d3_720w.jpg?source=1940ef5c)

   其中真阳率和伪阳率的定义非被为：

   tp-rate = tp / tp+fn 

   fp-rate = fp / fp+tn 

   其实TPRate就是TP除以TP所在的列，FPRate就是FP除以FP所在的列，二者意义如下：

   - **TPRate的意义是所有真实类别为1的样本中，预测类别为1的比例。**
   - **FPRate的意义是所有真实类别为0的样本中，预测类别为1的比例。**

   我们希望分类器达到的效果是：对于真实类别为1的样本，分类器预测为1的概率（即TPRate），要大于真实类别为0而预测类别为1的概率（即FPRate），即y＞x

   如何理解机器学习和统计中的AUC？ - 无涯的回答 - 知乎 https://www.zhihu.com/question/39840928/answer/241440370 

   

2. **分别随机从正负样本集中抽取一个正样本，一个负样本，正样本的预测值大于负样本的概率**

   另外一种说法： 

   AUC的概率意义是随机取一对正负样本，正样本得分大于负样本的概率

   ROC设计的初衷非常简单：随机选择一个正样本x，随机选择一个负样本y，丢给你的判别器来打分，AUC值就表示x比y更像正样本的概率。

   此时**auc的计算**上，可以简洁地表达为：

![[img]](https://www.zhihu.com/equation?tex=auc%3D%5Csum_%7Bx%5Cin+%E6%AD%A3%E6%A0%B7%E6%9C%AC%7D%7B%5Cfrac%7B1%7D%7B%E6%AD%A3%E6%A0%B7%E6%9C%AC%E6%80%BB%E6%95%B0%7D%5Ctimes%5Cfrac%7B%E7%BD%AE%E4%BF%A1%E5%BA%A6%E5%B0%8F%E4%BA%8Ex%E7%9A%84%E8%B4%9F%E6%A0%B7%E6%9C%AC%E4%B8%AA%E6%95%B0%7D%7B%E8%B4%9F%E6%A0%B7%E6%9C%AC%E6%80%BB%E6%95%B0%7D%7D)

​		根据古典概率模型

![img](https://pic1.zhimg.com/v2-33abc4c7d3ba5146701f60bea40ebc58_b.jpg)

​		即 就是统计概率 对每一个正样本x 看有多少小于x的负样本，即计算每一个概率即可 



​	由概率解释得到的AUC的一些性质：

- 样本得分都加上某个常数，AUC不变
- 对正负样本比例不敏感，意味着你可以用负采样后的样本进行模型评估也不会差太多



3. auc的局限性以及改进

   局限性： 衡量的是整体样本间的排序能力，即不同用户对不同item的排序能力，而线上很多更多关注同一个用户的不同item之间的排序能力。

   改进： 阿里在 [Deep Interest Network](https://zhuanlan.zhihu.com/p/37576578/edit)中提到一种改进版本的 AUC 指标，用户加权平均AUC（gAUC）更能反映线上真实环境的排序能力。



#### AUC的一些理解 

参考- 乱弹机器学习评估指标AUC - 吴海波的文章 - 知乎 https://zhuanlan.zhihu.com/p/52930683

##### 排序特性

AUC指标本身和模型预测score绝对值无关， 只关注排序效果

若采用precision、F1等指标，而模型预测的score是个概率值，就必须选择一个阈值来决定哪些样本预测是1哪些是0，不同的阈值选择，precision的值会不同。



##### 点击率模型的auc低于购买转化率模型的auc

业务理解，auc衡量的是正负样本之间的预测gap， 

通常，点击行为的成本要低于购买行为，从业务上理解，**点击率模型中正负样本的差别要小于购买力模型**，即购买转化模型的正样本通常更容易被预测准。



##### 线下AUC提升为什么不能带来线上效果提升？

可能出现的错误：

1.  **样本穿越**。比如样本中有时间序类的特征，但train、test的数据切分没有考虑时间因子，则容易造成穿越。
2.  前后特征对比没有出现重大失误情况 
3.  **线上的数据分布和线下的样本分布不对等**， 线上分布变化？
4.  auc指标失真？ 可以考虑加入gauc指标来判断 
5.  可能没有加入position bias 因素？ 



线下AUC提升为什么不能带来线上效果提升? - 萧瑟的文章 - 知乎 https://zhuanlan.zhihu.com/p/58152702

> 1. 样本角度
>
>    1. 线上出现了较多的新样本 ，线下是基于历史数据更新的 **数据分布的不一致**（冰山下的数据很大）
>    2. 前后代码不一致 **线上线下特征**不一致 代码前后不一致 要**同一套代码和数据源抽取特征**
>    3. 历史数据由老模型产生，本身也是由bias的
>    4. 线上和线下特征不一致。例如包含时间相关特征，存在**特征穿越** **样本穿越**。或者线上部分特征缺失等等
>
> 2. 评估目标
>
>    1. AUC计算的时候，不仅会涉及同一个用户的不同item，也会涉及不同用户的不同item，而**线上排序系统**每次排序只针对**同一个用户的不同item进行打分**。（auc的局限性和 gauc）
>    2. **线下没有考虑position等偏置元素** 线上效果只跟相关性有关，是和position等偏置因素无关的。而线下一般是不同position的样本混合训练，因此线上和线下评估不对等
>
> 3. 分布变化
>
>    线上有些出价策略依赖了打分分布，例如有一些相关阈值，那么就可能产生影响。这个可以绘制**CTR概率分布图**来检查。
>
> 4. 模型有较大变化的时候，例如lr->树模型，lr->深度模型，不同网络结构的深度模型变化，这种情况容易出现，原因就是新旧模型的变化较大，预估分数变化也较大。
>
> 
>
> **解决办法：**
>
> 1. **无偏样本**作为测试集。随机样本最好，不行的话，最好不要是基于老模型产生的线上样本 尽可能利用这些对新模型有利的样本
>
> 2. 使用gauc等指标
>
> 3. 线上线下模型融合  新模型预估分数 ![[公式]](https://www.zhihu.com/equation?tex=pctr_%7Bnew%7D) *和老模型预估分数* ![[公式]](https://www.zhihu.com/equation?tex=pctr_%7Bold%7D) 直接在线上做线性融合，刚上线的时候a选取比较小，随着慢慢迭代，a慢慢放大。
>
>    ![[公式]](https://www.zhihu.com/equation?tex=pctr%3Da%2Apctr_%7Bnew%7D+%2B+%281-a%29%2Apctr_%7Bold%7D)



#### f1-score 

F1 score是精确率和召回率的调和平均

![img](https://pic3.zhimg.com/80/v2-9fc7869cc3d89aa80d6fe45cd8d9b8aa_720w.jpg)

<img src="https://img-blog.csdnimg.cn/20190420235609890.png" alt="在这里插入图片描述" style="zoom:50%;" />

注意： 是* 1/2 原来记错了 



#### NDCG

