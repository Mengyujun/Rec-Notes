### 拼多多 拼越计划 8.08 19：00 

推荐算法： 

1. 介绍项目 
3. 用到了哪些召回方式？ 
4. auc是什么意思 ？ 
5. 正负样本的选择 主要是负样本的确定 包含哪些负样本  (训练数据都是使用的曝光之后的数据 即负样本就是曝光未点击样本)
6. 双塔dnn的大致结构 中间是什么？ 
7. 编程题： 长方形的交叉面积计算 （直接去找她们的点 左下和右上的点）





### 作业帮 8.10 一面

两道算法题：

1. 给出一个数组A（元素为非负整数）, 返回**最长严格递增子序列**的长度， 时间复杂读O(nlogn)  出现过几次的问题了

   ![image-20200810151940407](C:\Users\MYJ\AppData\Roaming\Typora\typora-user-images\image-20200810151940407.png)

2. 单调栈的问题 ： 给出一个数组nums， 大小为n， 返回数组同等大小的数组， 满足以下要求：
     对于数组nums 中第i个元素，找到nums从第i+1 到 第n个元素第一个大于nums[i]的元素记为j，如果不存在j=-1
     最后返回所有的j构成的数组 

   ![image-20200810151925513](C:\Users\MYJ\AppData\Roaming\Typora\typora-user-images\image-20200810151925513.png)



具体项目问题：

1.  如何评估单特征实验的效果呢？ auc+case分析 
2. cart树 的 能继续使用这个特征分类嘛 特征选择的问题 



### 快手一面 8.15

auc的计算公式 auc的缺点 如何改进

召回率和精确率的定义 

f1-score的计算公式 



两道算法题目：

括号匹配 最长匹配括号长度 （leetcode32）

路径最大和 



### 快手二面 8.18 

auc以及gauc的东西

在LR中对连续值得两种处理方式的区别以及选择 （1种是连续值 1种是离散化处理） 就是线性和非线性得选择 离散化之后相当于加了非线性得东西 



LR 逻辑回归中得交叉熵的表达： 

xi，yi的交叉熵的形式 

sigmoid函数的导数 



算法题 快排的时间复杂度 空间复杂度 best worst ave的不同情况 



### 拼多多 8.21 二面

召回的方式

项目数据流处理的过程

auc和gauc的区别 以及gauc具体按照什么维度 

项目过程中遇到的问题 

如何自学的 

用到了哪些评价指标



机器学习- 集成学习以及 决策树 还有svm 的相关知识 



算法题找中位数（其实就是top-k问题 参见leetcode.md 文件中的方法3 很简洁的方式 ）





### 京东 8.28 一二面

决策树相关知识 id3和c4.5的区别 熵的公式 

LR相关知识  lr的损失函数

svm相关知识 讲一下svm

gbdt相关知识 xgboost 相关知识

fm相关知识 fm和lr的关系 

deepfm的设计 为什么这么设计 有什么好处 

wide&deep的设计原因  两部分分别的作用 

简历上的东西一定要十分熟悉 cnn 有什么操作 有什么含义？以及lstm只要你写上去的 都要很详尽的了解到

深度学习防止过拟合的方式 BN以及dropout 的操作含义以及好处 

深度学习相关知识 dcn cross层 

经典的推荐算法学习 

项目的评价指标



算法题：

[盛最多水的容器](https://leetcode-cn.com/problems/container-with-most-water) 

给定一个全由xy组成的字符串, 找到含有相同数量xy的最长连续子串长度，例如"xxyyxyyy"，x和y数量相等的最长子串是"xxyyxy"，长度为6



### 8.29oppo 笔试题

SGD具体什么意思 随机在哪？训练速度相关 和batch-gd的对比  这几个优化器的对比 

**fm和LR的区别**， **fm的公式**  fm优势相较于LR在哪 ？

L1和L2距离（即欧几里得距离 其实没有系数 就是根号下的平方和）的计算 

随机森林的随机性体现在哪？ 

评价指标 MSE 交叉熵的公式  以及相关的评价指标以及计算 

皮尔孙相关系数的计算公式 

cnn卷积的计算 卷积之后的特征图的大小 以及 对卷积的理解  卷积操作 大小卷积核之间的区别 

问到了 knn和kmeans的区别 k的不同 

泛化能力什么意思 

完全二叉树的定义 明确一下 



### 9.3 新浪面试

新浪面试准备：

听到的算法有deepFM 、deepFFM （要手写了公式）、BERT原理，attention机制
他们这边现在线上用的模型是deepMCP+mmoe
还有dcn

召回的双塔dnn



具体面试： 

one-hot 和embedding的区别 什么造成了差异

auc的计算 

过拟合 如何解决过拟合 

手写 LR的假设函数 loss函数 以及求偏导 （出现了问题）

用python写kmeans 用mapreduce来优化 



### 9.5 360面试

auc和gauc auc提高但gauc下降的原因（用户group的区分度加大 但是单用户的区分并不大）

负样本采样? 选择什么作为负样本 两种采样方式的区别 对指标的影响 对模型的影响 （对全局的负样本采样呢 使得模型学的很简单，即可能指标很高，但是区分度不高，不足以作为rank的排序，因此通常作为召回的采样方式，  ）

mse作为loss的 和交叉熵的对比  有何区别   mse假设是什么分布(高斯分布也即正态分布)

熵和交叉熵 

你作为推荐算法工程的优势是？ 



### 9.4 美团面试 

dnn 双塔

召回方式 多少路召回

dcn的缺点有哪些  dcn deepfm相对于之前的优势 

xgboost了解？ 

多目标任务学习？ mmoe

图计算是否了解 

数据倾斜了解嘛？



### 9.6 aml面试



auc提升，线上一定提升嘛？ 为什么？

梯度爆炸的原因NaN 如何解决 

LSTM解决什么问题 如何解决

GBDT 介绍 分类时候呢？ 

LR的loss 极大似然估计？ 什么分布 

fm和deepfm模型  对比 训练时间的差异 模型训练的不同 哪一个效果好 

上线之后 对整个模型的影响 指标会上升还是下降？ （开放式）

某个召回的ctr高，然后放大曝光量之后，就一定会提升模型指标嘛？（不一定？）



### 9.12 pdd

常规问题： gbdt xgboost lr 相关知识 优化器 激活函数 梯度消失梯度爆炸 bagging和boosting

时长回归模型的负样本？ 

召回方式了解多少 

**以及双塔dnn具体细节 需要掌握 label如何设计的？**

召回 多兴趣召回 阿里的模型  粗排- **模型蒸馏** 精排-din相关 

