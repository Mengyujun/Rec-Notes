### **spark中用过哪些算子？ group_by 和reduceby_key的区别 ？**

算子类型 :https://www.cnblogs.com/kpsmile/p/10434390.html

reduceByKey用于对每个key对应的多个value进行merge操作，最重要的是它能够在本地先进行merge操作，并且merge操作可以通过函数自定义

也就是，groupByKey也是对每个key进行操作，但只生成一个sequence

**不同点：**
1， groupByKey默认没有聚合函数，得到的返回值类型是RDD[ k,Iterable[V]]
2， reduceByKey 必须传聚合函数 得到的返回值类型 RDD[(K,聚合后的V)]
3， groupByKey().map() = reduceByKey



如果需要对sequence进行aggregation操作（注意，groupByKey本身不能自定义操作函数），那么，选reduceByKey/aggregateByKey更好。这是因为groupByKey不能自定义函数，我们需要先用groupByKey生成RDD，然后才能对此RDD通过map进行自定义函数操作。

为什么reduce优于group，见下图

reduce会先在**本地进行merge操作**，并且merge操作支持自定义

使用redecebykey时，reduceByKey中的lamdba函数被调用两次，一次是在同一机器上，一次是在汇总时



![img](https://img-blog.csdn.net/20151121161604854?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

采用groupByKey时，由于它不接收函数，spark只能先将所有的键值对(key-value pair)都移动，这样的后果是集群节点之间的开销很大，导致传输延时。

![img](https://img-blog.csdn.net/20151121162115121?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)



### Spark数据倾斜

参见链接-Spark性能优化指南——高级篇 - 美团技术团队的文章 - 知乎 https://zhuanlan.zhihu.com/p/22024169

#### 数据倾斜发生时的现象

- 绝大多数task执行得都非常快，但个别task执行极慢。比如，总共有1000个task，997个task都在1分钟之内执行完了，但是剩余两三个task却要一两个小时。这种情况很常见。
- 原本能够正常执行的Spark作业，某天突然报出OOM（内存溢出）异常，观察异常栈，是我们写的业务代码造成的。这种情况比较少见。

#### 数据倾斜发生的原理

数据倾斜的原理很简单：在进行**shuffle**的时候，必须将各个节点上**相同的key拉取到某个节点上的一个task**来进行处理，比如按照key进行聚合或join等操作。此时如果某个key对应的数据量特别大的话，就会发生数据倾斜。比如大部分key对应10条数据，但是个别key却对应了100万条数据，那么大部分task可能就只会分配到10条数据，然后1秒钟就运行完了；但是个别task可能分配到了100万数据，要运行一两个小时。因此，整个Spark作业的运行进度是由**运行时间最长的那个task**决定的。

因此出现数据倾斜的时候，Spark作业看起来会运行得非常缓慢，甚至可能因为**某个task处理的数据量过大**导致内存溢出。



#### 定位导致数据倾斜的代码

数据倾斜只会发生在shuffle过程中。这里给大家罗列一些常用的并且可能会触发shuffle操作的算子：distinct、groupByKey、reduceByKey、aggregateByKey、join、cogroup、repartition等。出现数据倾斜时，可能就是你的代码中使用了这些算子中的某一个所导致的。

知道了数据倾斜发生在哪里之后，通常需要分析一下那个执行了shuffle操作并且导致了数据倾斜的RDD/Hive表，查看一下其中**key的分布情况。**

#### 数据倾斜的解决方案

1. ​	hive etl 提前拦截 

   通过Hive来进行数据预处理（即通过Hive ETL预先对数据按照key进行聚合，或者是预先和其他表进行join）

   **方案实现原理**：这种方案从根源上解决了数据倾斜，因为彻底避免了在Spark中执行shuffle类算子，那么肯定就不会有数据倾斜的问题了。但是这里也要提醒一下大家，这种方式属于治标不治本。因为毕竟数据本身就存在分布不均匀的问题，所以Hive ETL中进行group by或者join等shuffle操作时，还是会出现数据倾斜，导致Hive ETL的速度很慢。我们只是把数据倾斜的发生提前到了Hive ETL中，避免Spark程序发生数据倾斜而已。

   **方案优点：**实现起来简单便捷，效果还非常好，完全规避掉了数据倾斜，Spark作业的性能会大幅度提升。

   **方案缺点：**治标不治本，Hive ETL中还是会发生数据倾斜。

2. 过滤少数导致倾斜的key 

   **方案实现原理：**将导致数据倾斜的key给过滤掉之后，这些key就不会参与计算了，自然不可能产生数据倾斜。

   **方案优点：**实现简单，而且效果也很好，可以完全规避掉数据倾斜。

   **方案缺点：**适用场景不多，大多数情况下，导致倾斜的key还是很多的，并不是只有少数几个。

3. 提高shuffle操作的并行度 

   **方案实现思路：**在对RDD执行shuffle算子时，给shuffle算子传入一个参数，比如reduceByKey(1000)，该参数就设置了这个shuffle算子执行时shuffle read task的数量。 

   **方案优点：**实现起来比较简单，可以有效缓解和减轻数据倾斜的影响。

   **方案缺点：**只是缓解了数据倾斜而已，没有彻底根除问题，根据实践经验来看，其效果有限。 

4. **两阶段聚合（局部聚合+全局聚合）**

   **方案适用场景：**对RDD执行**reduceByKey**等聚合类shuffle算子或者在Spark SQL中使用**group by**语句进行分组聚合时，比较适用这种方案。

   **方案实现思路：**这个方案的核心实现思路就是进行两阶段聚合。第一次是局部聚合，先给每个key都打上一个随机数，比如10以内的随机数，此时原先一样的key就变成不一样的了 ，局部聚合，最后取消前缀，重新进行全局的聚合 

   **方案优点：**对于聚合类的shuffle操作导致的数据倾斜，效果是非常不错的。**通常都可以解决掉数据倾斜**，或者至少是大幅度缓解数据倾斜，将Spark作业的性能提升数倍以上。

   **方案缺点：**仅仅适用于聚合类的shuffle操作，适用范围相对较窄。如果是join类的shuffle操作，还得用其他的解决方案。

   ![img](https://picb.zhimg.com/2ddcc3aab8dba2f4455a45ef38e6f6c0_b.jpg)

5. 将reduce join 转化为 map join

   **方案适用场景：**在对RDD使用**join类操作**，或者是在Spark SQL中使用join语句时，而且join操作中的一个RDD或表的数据量比较小（比如几百M或者一两G），比较适用此方案。

   **方案实现原理：**普通的join是会走shuffle过程的，而一旦shuffle，就相当于会将相同key的数据拉取到一个shuffle read task中再进行join，此时就是reduce join。但是如果一个RDD是比较小的，则可以采用广播小RDD全量数据+map算子来实现与join同样的效果，也就是map join，此时就不会发生shuffle操作，也就不会发生数据倾斜。具体原理如下图所示。

   **方案优点：**对join操作导致的数据倾斜，效果非常好，因为根本就不会发生shuffle，也就根本不会发生数据倾斜。

   **方案缺点：**适用场景较少，因为这个方案只适用于一个大表和一个小表的情况。毕竟我们需要将小表进行广播，此时会比较消耗内存资源

6. 采样倾斜key并分拆join操作  （有点方案4的感觉）

   **方案实现原理：**对于join导致的数据倾斜，如果只是某几个key导致了倾斜，可以将少数几个key分拆成独立RDD，并附加随机前缀打散成n份去进行join，此时这几个key对应的数据就不会集中在少数几个task上，而是分散到多个task进行join了。具体原理见下图。

   **方案优点：**对于join导致的数据倾斜，如果只是某几个key导致了倾斜，采用该方式可以用最有效的方式打散key进行join。而且只需要针对少数倾斜key对应的数据进行扩容n倍，不需要对全量数据进行扩容。避免了占用过多内存。

   **方案缺点：**如果导致倾斜的key特别多的话，比如成千上万个key都导致数据倾斜，那么这种方式也不适合。

   ![img](https://pic2.zhimg.com/8912cfe355074e380112b57ce9f30071_b.jpg)

7. 使用随机前缀和扩容RDD进行join

   参见链接

8. 整合以上方法

   

