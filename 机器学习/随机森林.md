# 随机森林



### 随机森林的随机性-两个随机采样

1. 随机数据（在构建树时对训练数据点进行随机抽样） -- 每次都是有放回的取N个样本 不同决策树的训练样本集是不同的
2. 随机特征（分割节点时考虑特征的随机子集） -- 在**每次**节点分裂时，当每个样本有M个属性时，随机从这M个属性中选取出m个属性，满足条件m << M，然后从m个属性中采用某种策略来 作为分裂属性 

随机森林的特征构造过程是完全分裂的， 即--决策树的某一个叶子节点要么是无法继续分裂的，要么里面的所有样本的都是指向的同一个分类， 同时两次随机采样已经能够避免过拟合，因此不需要**剪枝**



### 随机森林的优点

1. 两个随机性的引入 使得不容易出现过拟合，很好的抗噪能力，且不需要剪枝
2. 决策树的优点- 简单 训练速度快  实现简单 容易理解 容易解释
3. bagging算法的优点 容易做成并行化的方法 
4. bagging的思想 通过多个低偏差，高方差的树结合，**降低方差** 
5. 调参简单 



### 随机森林的缺点

1. 比较难学习到组合特征
2.  本质上是一种启发式搜索，每一次split都是做出一次局部最优的选择，最终结果并不能保证全局最优。