## 连续特征离散化

举例： 

在工业界，很少直接将**连续值**作为**逻辑回归模型**的特征输入，而是将连续特征离散化为一系列0、1特征交给逻辑回归模型



> 李沐曾经说过：模型是使用离散特征还是连续特征，其实是一个“海量离散特征+简单模型” 同 “少量连续特征+复杂模型”的权衡。既可以离散化用线性模型，也可以用连续特征加深度学习。就看是喜欢折腾特征还是折腾模型了。通常来说，前者容易，而且可以n个人一起并行做，有成功经验；后者目前看很赞，能走多远还须拭目以待。



### 连续特征离散化的优势？

1. 离散特征的增加和删减比较方便，有利于模型的迅速迭代
2. 稀疏向量 进行内积计算快 且结果方便存储 容易扩展
3. 离散化可以增强关于异常数据的**鲁棒性**，从数据的截断（低于一定值和高于一定值都会截断分桶）
4. 离散化相当于对数据 **分段**，从而引入了非线性，增强模型的表达能力
5. 离散化之后可以进行**特征交叉**，（不同年龄段和其他特征做交叉），进一步引入了非线性 
6. 离散化之后**模型稳定**了，还是一段区域内数据一个参数 



### 连续特征离散化的方法

#### 无监督离散化

1. 等宽法
2. 等频法
3. 聚类法 （kmeans）

#### 有监督方法

包含**1R方法、基于卡方的方法，基于信息熵的方法**





## 特征选择

机器学习中，有哪些特征选择的工程方法？ - 城东的回答 - 知乎 https://www.zhihu.com/question/28641663/answer/110165221